{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eb80efe5c67ca4b",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e12e3043630cc2b",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364307d8b772df3e",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import textblob\n",
    "import sklearn\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"scipy version: {sp.__version__}\")\n",
    "print(f\"textblob version: {textblob.__version__}\")\n",
    "print(f\"scikit-learn version: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b330695af2421cf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Extracción\n",
    "\n",
    "En esta sección, extraemos los datos de los archivos steam_games, user_items y user_reviews que estan en formato parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e986e99f45d7c4b7",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Cargamos los archivos parquet\n",
    "def read_parquet_files(parquet_files):\n",
    "    dataframes = {}\n",
    "    for name in parquet_files:\n",
    "        dataframes[name] = pd.read_parquet(f'../dataset/{name}.parquet', engine='pyarrow')\n",
    "    return dataframes\n",
    "\n",
    "\n",
    "parquet_files = ['steam_games', 'user_items', 'user_reviews']\n",
    "dataframes = read_parquet_files(parquet_files)\n",
    "\n",
    "# Convertimos a df.\n",
    "df_steam_games = dataframes['steam_games']\n",
    "df_user_items = dataframes['user_items']\n",
    "df_user_reviews = dataframes['user_reviews']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86834d89f100dec0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Vamos a añadir una columna ‘sentiment_analysis’ al dataset ‘user_reviews’ usando NLP para analizar el sentimiento de las reseñas de los juegos. Esto nos permitirá entender las opiniones de los usuarios. Las reseñas se calificarán de la siguiente manera:\n",
    "\n",
    "0: Negativa (insatisfacción, disgusto, decepción)\n",
    "1: Neutral (indiferencia, objetividad, sin emoción)\n",
    "2: Positiva (satisfacción, gusto, admiración)\n",
    "\n",
    "Crearemos una función **`analisis_sentimiento`** usando TextBlob para analizar el sentimiento de las reseñas de los juegos. Esta función se basará en la polaridad, que varía entre -1 y 1, para determinar si una reseña es negativa, neutra o positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa52402b4cf0402",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def analisis_sentimiento(review):\n",
    "    # Si la reseña está ausente, retorna 1 (neutral)\n",
    "    if pd.isnull(review):\n",
    "        return 1\n",
    "\n",
    "    # Calcula la polaridad de la reseña usando TextBlob\n",
    "    polarity = TextBlob(review).sentiment.polarity\n",
    "\n",
    "    # Retorna 0 (malo) si la polaridad es menor que 0, 2 (positivo) si la polaridad es mayor que 0, y 1 (neutral) en caso contrario\n",
    "    if polarity < 0:\n",
    "        return 0\n",
    "    elif polarity > 0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9130864df6b291a0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- Aplicamos la función a la columna review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853c1bec39c2091b",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_user_reviews.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d877eaf83e3f7",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_user_reviews['sentiment_analysis'] = df_user_reviews['review'].apply(analisis_sentimiento)\n",
    "df_user_reviews[['review','sentiment_analysis']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7794e043310a0c6e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Creación de Conjuntos de Datos para los Endpoints de la API\n",
    "\n",
    "Nuestro propósito en esta sección es establecer varios conjuntos de datos, actuando como bases de datos pseudo, para las funciones de los endpoints de la API. Esto nos permitirá recuperar los datos requeridos de manera rápida y eficaz, sin la necesidad de cargar toda la información, optimizando así el rendimiento de la API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdfab6a225126f6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Creación de la Pseudo Base de Datos 1\n",
    "####    (Endpoints de la API def PlayTimeGenre( genero : str ): y def UserForGenre( genero : str ):)\n",
    "Para formar un único conjunto de datos que sirva como pseudo base de datos para los endpoints, es necesario fusionar df_steam_games y df_user_items. De esta forma, consolidamos toda la información requerida en un solo lugar. Las columnas necesarias son: item_id, genres, release_year de df_steam_games y item_id, user_id, playtime_forever de df_user_items.\n",
    "\n",
    "1. Seleccionamos únicamente las columnas requeridas:\n",
    "```python\n",
    "steam_games_columns = ['item_id','genres','release_year']\n",
    "user_items_columns = ['item_id','user_id', 'playtime_forever']\n",
    "```\n",
    "2. Creamos subconjuntos de los DataFrames con solo las columnas necesarias:\n",
    "```python\n",
    "df_games_subset = df_steam_games[steam_games_columns]\n",
    "df_items_subset = df_user_items[user_items_columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f9a8adb464bf42",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "steam_games_columns = ['item_id','genres','release_year']\n",
    "user_items_columns = ['item_id','user_id', 'playtime_forever']\n",
    "\n",
    "df_games_subset = df_steam_games[steam_games_columns]\n",
    "df_items_subset = df_user_items[user_items_columns]\n",
    "\n",
    "\n",
    "\n",
    "df_endpoints1_2 = pd.merge(df_games_subset, df_items_subset, on='item_id')\n",
    "df_endpoints1_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c373077a91e96",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Seleccionamos los 10 géneros mas frecuentes\n",
    "top_10_popular_genres = ['Action', 'Adventure', 'Indie', 'Strategy', 'RPG', 'Simulation', 'Casual', 'Massively Multiplayer', 'Racing', 'Sports']\n",
    "\n",
    "# Filtramos por las condiciones establecidas\n",
    "df_endpoints1_2 = df_endpoints1_2[(df_endpoints1_2['release_year'] != 'unknown') & (df_endpoints1_2['playtime_forever'] > 0)].reset_index(drop=True)\n",
    "df_endpoints1_2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
